# Video Analytics Chatbot

A natural language interface for querying video analytics data using AI-powered text-to-SQL conversion.

## Features

- **Natural Language Queries**: Ask questions in plain English
- **AI-Powered SQL Generation**: Automatic conversion to DuckDB SQL
- **Interactive Results**: View data tables and AI-generated summaries
- **Corporate Design**: Clean, professional interface
- **Star Schema Support**: Optimized for facts + dimensions data model

## Prerequisites

1. **Python 3.9+**
2. **Parquet data files** generated by the UnifiedPipeline
3. **API Key** from Anthropic (Claude) or OpenAI

## Installation

### 1. Install Dependencies

```bash
cd chatbot
pip install -r requirements.txt
```

### 2. Configure API Key

Copy the example environment file:
```bash
copy .env.example .env
```

Edit `.env` and add your API key:
```
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

Or for OpenAI:
```
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
```

### 3. Ensure Data Exists

Run the UnifiedPipeline to generate Parquet files:
```bash
cd ../UnifiedPipeline/scripts
python 5_to_parquet.py
```

Expected files:
- `UnifiedPipeline/output/parquet/facts/daily_analytics_all.parquet`
- `UnifiedPipeline/output/parquet/dimensions/video_metadata.parquet`

## Running the Application

```bash
cd chatbot
streamlit run app.py
```

The application will open in your browser at `http://localhost:8501`

## Usage

### Example Questions

- "What are the top 10 videos by total views?"
- "Show views by device type"
- "Which channels have the most videos?"
- "What's the average engagement score by channel?"
- "Show me videos with completion rate above 50%"
- "How many views did we get last month?"
- "Which videos have the longest watch time?"

### Tips

1. **Be specific**: "Top 10 videos by views in 2025" works better than "best videos"
2. **Use time filters**: "last month", "in 2024", "since January"
3. **Ask for aggregations**: "total", "average", "count", "by channel"

## Project Structure

```
chatbot/
├── app.py              # Main Streamlit application
├── config.py           # Configuration settings
├── database.py         # DuckDB connection and queries
├── llm.py              # LLM provider integration
├── requirements.txt    # Python dependencies
├── .env.example        # Environment template
└── README.md           # This file
```

## Configuration

Edit `config.py` to customize:

- **Colors**: Modify the `COLORS` dict for different branding
- **Models**: Change `ANTHROPIC_MODEL` or `OPENAI_MODEL`
- **Paths**: Adjust `DATA_DIR` if Parquet files are elsewhere

## Data Schema

### Facts Table (daily_analytics)
Daily metrics per video:
- `video_id`, `date`, `year`
- `video_view`, `views_desktop`, `views_mobile`, `views_tablet`
- `video_impression`, `play_rate`, `engagement_score`
- `video_engagement_1` through `video_engagement_100`
- `video_seconds_viewed`

### Dimensions Table (video_metadata)
One row per video:
- `video_id`, `name`, `channel`, `account_id`
- `video_duration`, `video_duration_seconds`
- `created_at`, `published_at`
- `video_category`, `business_unit`, `language`

## Troubleshooting

### "Data Not Available"
- Ensure Parquet files exist in `UnifiedPipeline/output/parquet/`
- Run `python 5_to_parquet.py` to generate them

### "API Key Not Configured"
- Create `.env` file from `.env.example`
- Add your API key
- Restart the application

### Query Errors
- Check the generated SQL in the response
- Try rephrasing your question
- Use simpler, more direct questions

## Cost Estimation

With Claude Sonnet or GPT-4o-mini:
- ~$0.002-0.005 per query
- 1,000 queries ≈ $2-5

## Security Notes

- API keys are loaded from environment variables (not hardcoded)
- Only SELECT queries are allowed (no data modification)
- SQL injection prevention through query validation
