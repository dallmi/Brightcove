{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Video Analytics Executive Dashboard\n",
    "\n",
    "**Purpose:** Provide actionable insights for Communication Specialists, Data Scientists, and Senior Executives to understand video performance and content strategy effectiveness.\n",
    "\n",
    "## Key Questions This Notebook Answers:\n",
    "1. **Performance:** Which videos are performing best? What are the trends?\n",
    "2. **Engagement:** Are viewers watching videos to completion? Where do they drop off?\n",
    "3. **Content Strategy:** What video lengths and content types drive the most engagement?\n",
    "4. **Platform Usage:** How are viewers accessing content (desktop vs mobile)?\n",
    "5. **Content Lifecycle:** Which content is stale and needs attention?\n",
    "6. **Account Comparison:** How do different channels/accounts compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Connect to DuckDB\n",
    "DB_PATH = Path('../output/analytics.duckdb')\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}. Run the pipeline first.\")\n",
    "\n",
    "conn = duckdb.connect(str(DB_PATH), read_only=True)\n",
    "print(f\"Connected to: {DB_PATH}\")\n",
    "print(f\"Database size: {DB_PATH.stat().st_size / (1024*1024):.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-overview",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Executive Summary\n",
    "High-level KPIs and trends at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Performance Indicators\n",
    "kpi_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(DISTINCT video_id) as total_videos,\n",
    "    COUNT(DISTINCT channel) as total_channels,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 2) as avg_engagement_score,\n",
    "    ROUND(AVG(video_percent_viewed), 2) as avg_percent_viewed,\n",
    "    MIN(date) as data_from,\n",
    "    MAX(date) as data_to,\n",
    "    COUNT(DISTINCT date) as days_of_data\n",
    "FROM daily_analytics\n",
    "\"\"\"\n",
    "kpis = conn.execute(kpi_query).fetchdf()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"           EXECUTIVE SUMMARY - KEY METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Total Videos Tracked:     {kpis['total_videos'].iloc[0]:,}\")\n",
    "print(f\"  Total Channels/Accounts:  {kpis['total_channels'].iloc[0]:,}\")\n",
    "print(f\"  Total Video Views:        {kpis['total_views'].iloc[0]:,}\")\n",
    "print(f\"  Avg Engagement Score:     {kpis['avg_engagement_score'].iloc[0]:.1f}%\")\n",
    "print(f\"  Avg Percent Viewed:       {kpis['avg_percent_viewed'].iloc[0]:.1f}%\")\n",
    "print(f\"\\n  Data Period: {kpis['data_from'].iloc[0]} to {kpis['data_to'].iloc[0]}\")\n",
    "print(f\"  ({kpis['days_of_data'].iloc[0]} days of data)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-trends",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly View Trends\n",
    "monthly_query = \"\"\"\n",
    "SELECT\n",
    "    DATE_TRUNC('month', date) as month,\n",
    "    SUM(video_view) as total_views,\n",
    "    COUNT(DISTINCT video_id) as unique_videos_viewed,\n",
    "    ROUND(AVG(engagement_score), 2) as avg_engagement\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "monthly = conn.execute(monthly_query).fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Views trend\n",
    "axes[0].bar(monthly['month'].astype(str), monthly['total_views'], color='steelblue', alpha=0.8)\n",
    "axes[0].set_title('Monthly Video Views', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Total Views')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# Engagement trend\n",
    "axes[1].plot(monthly['month'].astype(str), monthly['avg_engagement'], marker='o', linewidth=2, color='coral')\n",
    "axes[1].set_title('Monthly Average Engagement Score', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Engagement Score (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-top-performers",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Top Performing Content\n",
    "Which videos are driving the most views and engagement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-videos-views",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 Videos by Total Views\n",
    "top_views_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_percent_viewed), 1) as avg_completion,\n",
    "    MIN(date) as first_view_date,\n",
    "    MAX(date) as last_view_date\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel, video_id\n",
    "ORDER BY total_views DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "top_videos = conn.execute(top_views_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    TOP 20 VIDEOS BY TOTAL VIEWS\")\n",
    "print(\"=\"*80)\n",
    "display(top_videos[['channel', 'video_name', 'total_views', 'avg_engagement', 'avg_completion']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-videos-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Videos by Engagement (minimum 100 views for statistical significance)\n",
    "top_engagement_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_percent_viewed), 1) as avg_completion,\n",
    "    ROUND(AVG(video_engagement_100), 1) as pct_watched_100\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel, video_id\n",
    "HAVING SUM(video_view) >= 100\n",
    "ORDER BY avg_engagement DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "top_engagement = conn.execute(top_engagement_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"         TOP 20 VIDEOS BY ENGAGEMENT (min 100 views)\")\n",
    "print(\"=\"*80)\n",
    "display(top_engagement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-engagement",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Engagement Analysis\n",
    "Understanding viewer behavior: Where do viewers drop off? What drives completion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engagement-funnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement Funnel Analysis\n",
    "funnel_query = \"\"\"\n",
    "SELECT\n",
    "    ROUND(AVG(video_engagement_1), 2) as started,\n",
    "    ROUND(AVG(video_engagement_25), 2) as reached_25pct,\n",
    "    ROUND(AVG(video_engagement_50), 2) as reached_50pct,\n",
    "    ROUND(AVG(video_engagement_75), 2) as reached_75pct,\n",
    "    ROUND(AVG(video_engagement_100), 2) as completed\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "\"\"\"\n",
    "funnel = conn.execute(funnel_query).fetchdf()\n",
    "\n",
    "stages = ['Started (1%)', 'Reached 25%', 'Reached 50%', 'Reached 75%', 'Completed (100%)']\n",
    "values = funnel.iloc[0].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(stages[::-1], values[::-1], color=['#2ecc71', '#3498db', '#9b59b6', '#e74c3c', '#e67e22'][::-1])\n",
    "ax.set_xlabel('Percentage of Viewers (%)', fontsize=12)\n",
    "ax.set_title('Video Engagement Funnel\\nWhere Do Viewers Drop Off?', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values[::-1]):\n",
    "    ax.text(val + 2, bar.get_y() + bar.get_height()/2, f'{val:.1f}%', \n",
    "            va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Drop-off analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           ENGAGEMENT DROP-OFF ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Start to 25%:   {values[0] - values[1]:.1f}% drop-off\")\n",
    "print(f\"  25% to 50%:     {values[1] - values[2]:.1f}% drop-off\")\n",
    "print(f\"  50% to 75%:     {values[2] - values[3]:.1f}% drop-off\")\n",
    "print(f\"  75% to 100%:    {values[3] - values[4]:.1f}% drop-off\")\n",
    "print(f\"\\n  Overall Completion Rate: {values[4]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-content-strategy",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Content Strategy Analysis\n",
    "What content characteristics drive better performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video-length-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Length vs Engagement\n",
    "length_query = \"\"\"\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN video_duration <= 60 THEN '1. Under 1 min'\n",
    "        WHEN video_duration <= 180 THEN '2. 1-3 min'\n",
    "        WHEN video_duration <= 300 THEN '3. 3-5 min'\n",
    "        WHEN video_duration <= 600 THEN '4. 5-10 min'\n",
    "        WHEN video_duration <= 1200 THEN '5. 10-20 min'\n",
    "        WHEN video_duration <= 1800 THEN '6. 20-30 min'\n",
    "        ELSE '7. Over 30 min'\n",
    "    END as duration_bucket,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as completion_rate\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0 AND video_duration > 0\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "length_analysis = conn.execute(length_query).fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Views by duration\n",
    "axes[0].bar(length_analysis['duration_bucket'], length_analysis['total_views'], color='steelblue', alpha=0.8)\n",
    "axes[0].set_title('Total Views by Video Duration', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Video Duration')\n",
    "axes[0].set_ylabel('Total Views')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# Completion rate by duration\n",
    "axes[1].bar(length_analysis['duration_bucket'], length_analysis['completion_rate'], color='coral', alpha=0.8)\n",
    "axes[1].set_title('Completion Rate by Video Duration', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Video Duration')\n",
    "axes[1].set_ylabel('Completion Rate (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"              VIDEO LENGTH PERFORMANCE BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "display(length_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "content-type-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Type Performance (if available)\n",
    "content_type_query = \"\"\"\n",
    "SELECT\n",
    "    COALESCE(video_content_type, 'Unclassified') as content_type,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as completion_rate\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY 1\n",
    "HAVING SUM(video_view) >= 50\n",
    "ORDER BY total_views DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "content_types = conn.execute(content_type_query).fetchdf()\n",
    "\n",
    "if len(content_types) > 1:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"              CONTENT TYPE PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    display(content_types)\n",
    "else:\n",
    "    print(\"\\nNote: Content type data not available or not classified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-channels",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Channel/Account Performance Comparison\n",
    "How do different accounts perform against each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "channel-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Performance Overview\n",
    "channel_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(SUM(video_view) * 1.0 / COUNT(DISTINCT video_id), 0) as views_per_video,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as completion_rate\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel\n",
    "ORDER BY total_views DESC\n",
    "\"\"\"\n",
    "channels = conn.execute(channel_query).fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Views by channel\n",
    "colors = plt.cm.husl(np.linspace(0, 1, len(channels)))\n",
    "axes[0].barh(channels['channel'], channels['total_views'], color=colors)\n",
    "axes[0].set_title('Total Views by Channel', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Total Views')\n",
    "axes[0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Engagement by channel\n",
    "axes[1].barh(channels['channel'], channels['avg_engagement'], color=colors)\n",
    "axes[1].set_title('Average Engagement by Channel', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Engagement Score (%)')\n",
    "axes[1].set_xlim(0, 100)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"              CHANNEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-devices",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Device & Platform Analysis\n",
    "How are viewers accessing content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Breakdown\n",
    "device_query = \"\"\"\n",
    "SELECT\n",
    "    SUM(views_desktop) as desktop,\n",
    "    SUM(views_mobile) as mobile,\n",
    "    SUM(views_tablet) as tablet,\n",
    "    SUM(views_other) as other\n",
    "FROM daily_analytics\n",
    "\"\"\"\n",
    "devices = conn.execute(device_query).fetchdf()\n",
    "\n",
    "device_data = {\n",
    "    'Desktop': devices['desktop'].iloc[0],\n",
    "    'Mobile': devices['mobile'].iloc[0],\n",
    "    'Tablet': devices['tablet'].iloc[0],\n",
    "    'Other': devices['other'].iloc[0]\n",
    "}\n",
    "\n",
    "# Filter out zero values\n",
    "device_data = {k: v for k, v in device_data.items() if v > 0}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6']\n",
    "axes[0].pie(device_data.values(), labels=device_data.keys(), autopct='%1.1f%%', \n",
    "            colors=colors[:len(device_data)], startangle=90)\n",
    "axes[0].set_title('Views by Device Type', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "axes[1].bar(device_data.keys(), device_data.values(), color=colors[:len(device_data)])\n",
    "axes[1].set_title('Total Views by Device', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Views')\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "total_device_views = sum(device_data.values())\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           DEVICE BREAKDOWN SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for device, views in device_data.items():\n",
    "    pct = views / total_device_views * 100\n",
    "    print(f\"  {device:12} {views:>12,} views ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-trends",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Trends Over Time\n",
    "device_trend_query = \"\"\"\n",
    "SELECT\n",
    "    DATE_TRUNC('month', date) as month,\n",
    "    SUM(views_desktop) as desktop,\n",
    "    SUM(views_mobile) as mobile,\n",
    "    SUM(views_tablet) as tablet\n",
    "FROM daily_analytics\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "device_trends = conn.execute(device_trend_query).fetchdf()\n",
    "\n",
    "# Calculate percentages\n",
    "device_trends['total'] = device_trends['desktop'] + device_trends['mobile'] + device_trends['tablet']\n",
    "device_trends['desktop_pct'] = device_trends['desktop'] / device_trends['total'] * 100\n",
    "device_trends['mobile_pct'] = device_trends['mobile'] / device_trends['total'] * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(device_trends['month'].astype(str), device_trends['desktop_pct'], marker='o', label='Desktop', linewidth=2)\n",
    "ax.plot(device_trends['month'].astype(str), device_trends['mobile_pct'], marker='s', label='Mobile', linewidth=2)\n",
    "ax.set_title('Device Usage Trend Over Time', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Percentage of Views (%)')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-lifecycle",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Content Lifecycle Analysis\n",
    "Identify stale content and optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stale-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stale Content - Videos not viewed recently but still in library\n",
    "stale_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    MAX(dt_last_viewed) as last_viewed,\n",
    "    SUM(video_view) as total_views,\n",
    "    MAX(created_at)::DATE as created_date\n",
    "FROM daily_analytics\n",
    "WHERE dt_last_viewed IS NOT NULL\n",
    "GROUP BY channel, video_id\n",
    "HAVING MAX(dt_last_viewed)::DATE < CURRENT_DATE - INTERVAL '180 days'\n",
    "ORDER BY total_views DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "try:\n",
    "    stale_content = conn.execute(stale_query).fetchdf()\n",
    "    if len(stale_content) > 0:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"    STALE CONTENT ALERT: Videos Not Viewed in 180+ Days\")\n",
    "        print(\"    (Sorted by historical views - these had audience interest)\")\n",
    "        print(\"=\"*80)\n",
    "        display(stale_content)\n",
    "    else:\n",
    "        print(\"\\nNo stale content found (all videos viewed within 180 days).\")\n",
    "except:\n",
    "    print(\"\\nNote: dt_last_viewed data not available for stale content analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-content-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recent Content Performance (Last 30 Days)\n",
    "recent_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    SUM(video_view) as views_last_30d,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    MAX(created_at)::DATE as created_date\n",
    "FROM daily_analytics\n",
    "WHERE date >= CURRENT_DATE - INTERVAL '30 days'\n",
    "  AND video_view > 0\n",
    "GROUP BY channel, video_id\n",
    "ORDER BY views_last_30d DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "recent_content = conn.execute(recent_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"         TOP PERFORMING CONTENT (Last 30 Days)\")\n",
    "print(\"=\"*80)\n",
    "display(recent_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-recommendations",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Actionable Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Automated Insights\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"         ACTIONABLE INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Insight 1: Best performing video length\n",
    "if len(length_analysis) > 0:\n",
    "    best_length = length_analysis.loc[length_analysis['completion_rate'].idxmax()]\n",
    "    print(f\"\\n1. OPTIMAL VIDEO LENGTH\")\n",
    "    print(f\"   Highest completion rate: {best_length['duration_bucket']} ({best_length['completion_rate']:.1f}% completion)\")\n",
    "    print(f\"   Recommendation: Focus on creating videos in this duration range for maximum engagement.\")\n",
    "\n",
    "# Insight 2: Channel opportunities\n",
    "if len(channels) > 1:\n",
    "    high_engagement_low_views = channels[channels['avg_engagement'] > channels['avg_engagement'].median()]\n",
    "    high_engagement_low_views = high_engagement_low_views[high_engagement_low_views['total_views'] < channels['total_views'].median()]\n",
    "    if len(high_engagement_low_views) > 0:\n",
    "        print(f\"\\n2. UNDERUTILIZED HIGH-ENGAGEMENT CHANNELS\")\n",
    "        for _, row in high_engagement_low_views.iterrows():\n",
    "            print(f\"   - {row['channel']}: High engagement ({row['avg_engagement']:.1f}%) but lower views\")\n",
    "        print(f\"   Recommendation: Increase promotion of content from these channels.\")\n",
    "\n",
    "# Insight 3: Device strategy\n",
    "if device_data:\n",
    "    mobile_pct = device_data.get('Mobile', 0) / total_device_views * 100 if total_device_views > 0 else 0\n",
    "    print(f\"\\n3. MOBILE OPTIMIZATION\")\n",
    "    if mobile_pct > 30:\n",
    "        print(f\"   Mobile views: {mobile_pct:.1f}% of total traffic\")\n",
    "        print(f\"   Recommendation: Ensure all videos are mobile-optimized. Consider vertical video formats.\")\n",
    "    else:\n",
    "        print(f\"   Mobile views: {mobile_pct:.1f}% of total traffic\")\n",
    "        print(f\"   Recommendation: Desktop-first approach is appropriate. Consider mobile push to increase reach.\")\n",
    "\n",
    "# Insight 4: Engagement drop-off\n",
    "if funnel is not None and len(funnel) > 0:\n",
    "    first_drop = values[0] - values[1]\n",
    "    print(f\"\\n4. ENGAGEMENT OPTIMIZATION\")\n",
    "    print(f\"   Biggest drop-off: First 25% of video ({first_drop:.1f}% viewers leave)\")\n",
    "    print(f\"   Recommendation: Focus on stronger video openings. First 30 seconds are critical.\")\n",
    "\n",
    "# Insight 5: Content freshness\n",
    "print(f\"\\n5. CONTENT FRESHNESS\")\n",
    "if 'stale_content' in dir() and len(stale_content) > 0:\n",
    "    print(f\"   {len(stale_content)} videos haven't been viewed in 180+ days\")\n",
    "    print(f\"   Recommendation: Review stale content for archival, update, or re-promotion.\")\n",
    "else:\n",
    "    print(f\"   Content library appears fresh - good content lifecycle management!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-custom",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Custom Query Playground\n",
    "Use this section to run your own queries against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Query - Modify as needed\n",
    "custom_query = \"\"\"\n",
    "-- Example: Find videos with high impressions but low play rate\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    SUM(video_impression) as impressions,\n",
    "    SUM(video_view) as views,\n",
    "    ROUND(SUM(video_view) * 100.0 / NULLIF(SUM(video_impression), 0), 2) as play_rate\n",
    "FROM daily_analytics\n",
    "WHERE video_impression > 0\n",
    "GROUP BY channel, video_id\n",
    "HAVING SUM(video_impression) >= 100\n",
    "ORDER BY play_rate ASC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "custom_result = conn.execute(custom_query).fetchdf()\n",
    "print(\"Low Play Rate Videos (High Impressions, Low Clicks):\")\n",
    "print(\"These videos may need better thumbnails or titles.\\n\")\n",
    "display(custom_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "schema-reference",
   "metadata": {},
   "outputs": [],
   "source": "# Database Schema Reference\nschema_query = \"\"\"\nSELECT column_name, data_type\nFROM information_schema.columns\nWHERE table_name = 'daily_analytics'\nORDER BY ordinal_position\n\"\"\"\nschema = conn.execute(schema_query).fetchdf()\nprint(\"\\nAvailable Columns in daily_analytics table:\")\nprint(\"-\" * 50)\nfor _, row in schema.iterrows():\n    print(f\"  {row['column_name']:40} {row['data_type']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "1vwqio8ui7c",
   "source": "### Fuzzy Video Search\nSearch for videos by name using fuzzy matching (finds similar names even with typos).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j7cx65wi7sl",
   "source": "# Fuzzy Video Search Function\ndef fuzzy_search_videos(search_term, top_n=10, min_score=0.6):\n    \"\"\"\n    Search for videos using fuzzy string matching.\n    \n    Args:\n        search_term: String to search for\n        top_n: Number of results to return (default 10)\n        min_score: Minimum similarity score 0-1 (default 0.6)\n    \n    Returns:\n        DataFrame with top matching videos\n    \"\"\"\n    query = f\"\"\"\n    SELECT DISTINCT\n        video_id,\n        name,\n        channel,\n        jaro_winkler_similarity(name, '{search_term}') as similarity_score,\n        SUM(video_view) OVER (PARTITION BY video_id) as total_views,\n        ROUND(AVG(engagement_score) OVER (PARTITION BY video_id), 1) as avg_engagement,\n        MAX(created_at) OVER (PARTITION BY video_id)::DATE as created_date\n    FROM daily_analytics\n    WHERE jaro_winkler_similarity(name, '{search_term}') >= {min_score}\n    ORDER BY similarity_score DESC, total_views DESC\n    LIMIT {top_n}\n    \"\"\"\n    \n    results = conn.execute(query).fetchdf()\n    \n    if len(results) == 0:\n        print(f\"No videos found matching '{search_term}' with score >= {min_score}\")\n        print(\"Try lowering min_score (e.g., 0.4) or using different search terms.\")\n        return None\n    \n    return results\n\n\n# Example usage - modify search_term to search for different videos\nsearch_term = \"Quarterly Report\"  # Change this to search for different videos\nmin_similarity = 0.5  # Adjust this (0.0 - 1.0) - lower = more results but less accurate\n\nprint(f\"\\n{'='*80}\")\nprint(f\"  FUZZY SEARCH RESULTS FOR: '{search_term}'\")\nprint(f\"  (Similarity threshold: {min_similarity})\")\nprint(f\"{'='*80}\\n\")\n\nresults = fuzzy_search_videos(search_term, top_n=10, min_score=min_similarity)\n\nif results is not None:\n    # Format similarity score as percentage for readability\n    results['match_score'] = (results['similarity_score'] * 100).round(1).astype(str) + '%'\n    display_cols = ['match_score', 'name', 'channel', 'total_views', 'avg_engagement', 'created_date']\n    display(results[display_cols])\n    \n    print(f\"\\nFound {len(results)} matching video(s)\")\n    print(f\"\\nTip: Adjust 'search_term' and 'min_similarity' variables above to refine search.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "print(\"\\nDatabase connection closed.\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    END OF EXECUTIVE REPORT\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}