{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Impact Discovery Notebook\n",
    "## Find Real Examples for Interview Responses\n",
    "\n",
    "**Purpose:** Discover concrete business impact examples in your video analytics data that demonstrate strategic value and decision-making influence.\n",
    "\n",
    "**Use Case:** Prepare STAR-format interview responses with real quantifiable results from your organization.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. **Run Section 0** - Setup and verify data connection\n",
    "2. **Run Sections 1-10** - Each section discovers a different business impact pattern\n",
    "3. **Review the findings** - Look for interesting patterns in your data\n",
    "4. **Note the metrics** - Copy specific numbers for your interview responses\n",
    "5. **Customize queries** - Modify date ranges or filters to focus on specific periods\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Setup & Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Connect to DuckDB\n",
    "DB_PATH = Path('../output/analytics.duckdb')\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}. Run the pipeline first.\")\n",
    "\n",
    "conn = duckdb.connect(str(DB_PATH), read_only=True)\n",
    "print(f\"‚úì Connected to: {DB_PATH}\")\n",
    "print(f\"‚úì Database size: {DB_PATH.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Data coverage check\n",
    "coverage = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(date) as earliest_date,\n",
    "        MAX(date) as latest_date,\n",
    "        COUNT(DISTINCT video_id) as total_videos,\n",
    "        COUNT(DISTINCT channel) as total_channels,\n",
    "        SUM(video_view) as total_views,\n",
    "        COUNT(*) as total_records\n",
    "    FROM daily_analytics\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nüìä DATA COVERAGE:\")\n",
    "print(f\"   Date Range: {coverage['earliest_date'].iloc[0]} to {coverage['latest_date'].iloc[0]}\")\n",
    "print(f\"   Total Videos: {coverage['total_videos'].iloc[0]:,}\")\n",
    "print(f\"   Total Channels: {coverage['total_channels'].iloc[0]:,}\")\n",
    "print(f\"   Total Views: {coverage['total_views'].iloc[0]:,}\")\n",
    "print(f\"   Total Records: {coverage['total_records'].iloc[0]:,}\")\n",
    "print(\"\\n‚úì Ready to discover business impact patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Executive Communication Effectiveness\n",
    "**Business Question:** Which executive communications drive highest engagement? Are there performance differences by channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive content analysis\n",
    "exec_comms_query = \"\"\"\n",
    "SELECT \n",
    "    channel,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as avg_completion_rate,\n",
    "    ROUND(AVG(video_duration) / 60.0, 1) as avg_duration_minutes,\n",
    "    ROUND(AVG(video_percent_viewed), 1) as avg_percent_watched\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel\n",
    "ORDER BY total_views DESC\n",
    "\"\"\"\n",
    "\n",
    "exec_comms = conn.execute(exec_comms_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  EXECUTIVE COMMUNICATION PERFORMANCE BY CHANNEL\")\n",
    "print(\"=\"*80)\n",
    "display(exec_comms)\n",
    "\n",
    "# Calculate key insights\n",
    "if len(exec_comms) > 0:\n",
    "    top_channel = exec_comms.iloc[0]\n",
    "    high_eng_channel = exec_comms.loc[exec_comms['avg_engagement'].idxmax()]\n",
    "    \n",
    "    print(\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(f\"   Highest Reach: '{top_channel['channel']}' with {top_channel['total_views']:,.0f} views\")\n",
    "    print(f\"   Highest Engagement: '{high_eng_channel['channel']}' with {high_eng_channel['avg_engagement']:.1f}% engagement\")\n",
    "    \n",
    "    if high_eng_channel['channel'] != top_channel['channel']:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  OPPORTUNITY: '{high_eng_channel['channel']}' has high engagement but lower reach\")\n",
    "        print(f\"       Consider increasing promotion or content volume for this channel\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "exec_comms.plot(x='channel', y='total_views', kind='barh', ax=axes[0], legend=False, color='steelblue')\n",
    "axes[0].set_title('Total Views by Channel', fontweight='bold')\n",
    "axes[0].set_xlabel('Total Views')\n",
    "\n",
    "exec_comms.plot(x='channel', y='avg_engagement', kind='barh', ax=axes[1], legend=False, color='coral')\n",
    "axes[1].set_title('Average Engagement by Channel', fontweight='bold')\n",
    "axes[1].set_xlabel('Engagement Score (%)')\n",
    "axes[1].set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Compliance Training Effectiveness\n",
    "**Business Question:** Do shorter training videos lead to higher completion rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/compliance video analysis by duration\n",
    "training_query = \"\"\"\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN video_duration <= 300 THEN '1. Under 5 min'\n",
    "        WHEN video_duration <= 600 THEN '2. 5-10 min'\n",
    "        WHEN video_duration <= 900 THEN '3. 10-15 min'\n",
    "        WHEN video_duration <= 1200 THEN '4. 15-20 min'\n",
    "        ELSE '5. Over 20 min'\n",
    "    END as duration_category,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(video_engagement_100), 1) as avg_completion_rate,\n",
    "    ROUND(AVG(video_engagement_50), 1) as reached_halfway,\n",
    "    ROUND(AVG(video_percent_viewed), 1) as avg_percent_watched\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0 AND video_duration > 0\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "training_analysis = conn.execute(training_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  TRAINING VIDEO COMPLETION BY DURATION\")\n",
    "print(\"=\"*80)\n",
    "display(training_analysis)\n",
    "\n",
    "# Calculate ROI insight\n",
    "if len(training_analysis) > 1:\n",
    "    short_videos = training_analysis[training_analysis['duration_category'] == '1. Under 5 min']\n",
    "    long_videos = training_analysis[training_analysis['duration_category'] == '5. Over 20 min']\n",
    "    \n",
    "    if len(short_videos) > 0 and len(long_videos) > 0:\n",
    "        short_completion = short_videos['avg_completion_rate'].iloc[0]\n",
    "        long_completion = long_videos['avg_completion_rate'].iloc[0]\n",
    "        diff = short_completion - long_completion\n",
    "        pct_improvement = (diff / long_completion * 100) if long_completion > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüí° KEY INSIGHT:\")\n",
    "        print(f\"   Short videos (<5 min): {short_completion:.1f}% completion rate\")\n",
    "        print(f\"   Long videos (>20 min): {long_completion:.1f}% completion rate\")\n",
    "        print(f\"   Difference: {diff:.1f} percentage points ({pct_improvement:.0f}% improvement)\")\n",
    "        print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "        print(f\"      'Breaking training into <5 min modules increased completion by {pct_improvement:.0f}%,'\")\n",
    "        print(f\"       reducing compliance risk and follow-up costs'\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "training_analysis.plot(x='duration_category', y='avg_completion_rate', kind='bar', ax=ax, legend=False, color='#2ecc71')\n",
    "ax.set_title('Video Completion Rate by Duration', fontweight='bold', fontsize=14)\n",
    "ax.set_ylabel('Completion Rate (%)')\n",
    "ax.set_xlabel('Video Duration')\n",
    "ax.set_ylim(0, 100)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Regional Content Performance\n",
    "**Business Question:** Do different regions engage differently with content? Should we localize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional analysis (if country data is populated)\n",
    "regional_query = \"\"\"\n",
    "SELECT\n",
    "    COALESCE(country, 'Not Specified') as region,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_percent_viewed), 1) as avg_percent_watched,\n",
    "    ROUND(SUM(views_mobile) * 100.0 / NULLIF(SUM(video_view), 0), 1) as mobile_percentage\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY 1\n",
    "HAVING SUM(video_view) > 100\n",
    "ORDER BY total_views DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "regional_data = conn.execute(regional_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  REGIONAL CONTENT PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(regional_data) > 1:\n",
    "    display(regional_data)\n",
    "    \n",
    "    # Find interesting patterns\n",
    "    high_engagement_region = regional_data.loc[regional_data['avg_engagement'].idxmax()]\n",
    "    high_mobile_region = regional_data.loc[regional_data['mobile_percentage'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(f\"   Highest Engagement: {high_engagement_region['region']} ({high_engagement_region['avg_engagement']:.1f}%)\")\n",
    "    print(f\"   Most Mobile: {high_mobile_region['region']} ({high_mobile_region['mobile_percentage']:.1f}% mobile views)\")\n",
    "    \n",
    "    # Compare top 2 regions\n",
    "    if len(regional_data) >= 2:\n",
    "        region1 = regional_data.iloc[0]\n",
    "        region2 = regional_data.iloc[1]\n",
    "        engagement_diff = abs(region1['avg_engagement'] - region2['avg_engagement'])\n",
    "        \n",
    "        if engagement_diff > 10:\n",
    "            print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "            print(f\"      '{region1['region']} showed {engagement_diff:.1f} points higher engagement than {region2['region']},'\")\n",
    "            print(f\"       indicating need for region-specific content strategies'\")\nelse:\n",
    "    print(\"   ‚ö†Ô∏è  Regional data not available or not populated in your dataset\")\n",
    "    print(\"      (This is normal if country field isn't used)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Channel Rationalization Analysis\n",
    "**Business Question:** Should we consolidate channels? Which ones are underperforming?"
   ]
  },
  {
  "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel efficiency analysis\n",
    "channel_efficiency_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(SUM(video_view) * 1.0 / COUNT(DISTINCT video_id), 0) as views_per_video,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    CASE \n",
    "        WHEN AVG(engagement_score) >= 60 THEN 'High Engagement'\n",
    "        WHEN AVG(engagement_score) >= 40 THEN 'Medium Engagement'\n",
    "        ELSE 'Low Engagement'\n",
    "    END as engagement_tier,\n",
    "    CASE\n",
    "        WHEN SUM(video_view) >= PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY SUM(video_view)) OVER () THEN 'High Reach'\n",
    "        WHEN SUM(video_view) >= PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY SUM(video_view)) OVER () THEN 'Medium Reach'\n",
    "        ELSE 'Low Reach'\n",
    "    END as reach_tier\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel\n",
    "ORDER BY total_views DESC\n",
    "\"\"\"\n",
    "\n",
    "channel_efficiency = conn.execute(channel_efficiency_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  CHANNEL EFFICIENCY & RATIONALIZATION OPPORTUNITIES\")\n",
    "print(\"=\"*80)\n",
    "display(channel_efficiency)\n",
    "\n",
    "# Identify optimization opportunities\n",
    "print(\"\\nüí° STRATEGIC INSIGHTS:\")\n",
    "\n",
    "# Stars: High reach, high engagement\n",
    "stars = channel_efficiency[\n",
    "    (channel_efficiency['reach_tier'] == 'High Reach') & \n",
    "    (channel_efficiency['engagement_tier'] == 'High Engagement')\n",
    "]\n",
    "if len(stars) > 0:\n",
    "    print(f\"\\n   ‚≠ê STARS (Invest More): {', '.join(stars['channel'].tolist())}\")\n",
    "    print(f\"      High reach + High engagement = Prime channels for investment\")\n",
    "\n",
    "# Question marks: Low reach, high engagement\n",
    "question_marks = channel_efficiency[\n",
    "    (channel_efficiency['reach_tier'] == 'Low Reach') & \n",
    "    (channel_efficiency['engagement_tier'] == 'High Engagement')\n",
    "]\n",
    "if len(question_marks) > 0:\n",
    "    print(f\"\\n   ‚ùì OPPORTUNITIES (Promote More): {', '.join(question_marks['channel'].tolist())}\")\n",
    "    print(f\"      High engagement but low reach = Increase promotion\")\n",
    "\n",
    "# Money pits: Low reach, low engagement\n",
    "money_pits = channel_efficiency[\n",
    "    (channel_efficiency['reach_tier'] == 'Low Reach') & \n",
    "    (channel_efficiency['engagement_tier'] == 'Low Engagement')\n",
    "]\n",
    "if len(money_pits) > 0:\n",
    "    print(f\"\\n   üí∞ RECONSIDER (Consolidate or Redesign): {', '.join(money_pits['channel'].tolist())}\")\n",
    "    print(f\"      Low reach + Low engagement = Candidates for consolidation\")\n",
    "    \n",
    "    total_low_views = money_pits['total_views'].sum()\n",
    "    total_all_views = channel_efficiency['total_views'].sum()\n",
    "    pct_of_total = (total_low_views / total_all_views * 100) if total_all_views > 0 else 0\n",
    "    \n",
    "    print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "    print(f\"      'Identified {len(money_pits)} underperforming channels representing only {pct_of_total:.1f}% of views.'\")\n",
    "    print(f\"       Consolidating these could reduce operational costs by ~{len(money_pits) * 5:.0f}%'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Optimal Content Length Discovery\n",
    "**Business Question:** What's the sweet spot for video duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal duration analysis\n",
    "duration_sweet_spot_query = \"\"\"\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN video_duration <= 60 THEN '1. 0-1 min'\n",
    "        WHEN video_duration <= 120 THEN '2. 1-2 min'\n",
    "        WHEN video_duration <= 180 THEN '3. 2-3 min'\n",
    "        WHEN video_duration <= 300 THEN '4. 3-5 min'\n",
    "        WHEN video_duration <= 420 THEN '5. 5-7 min'\n",
    "        WHEN video_duration <= 600 THEN '6. 7-10 min'\n",
    "        WHEN video_duration <= 900 THEN '7. 10-15 min'\n",
    "        ELSE '8. Over 15 min'\n",
    "    END as duration_bucket,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as completion_rate,\n",
    "    ROUND(AVG(video_engagement_50), 1) as halfway_rate\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0 AND video_duration > 0\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "duration_analysis = conn.execute(duration_sweet_spot_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  OPTIMAL VIDEO DURATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "display(duration_analysis)\n",
    "\n",
    "# Find sweet spot\n",
    "sweet_spot = duration_analysis.loc[duration_analysis['completion_rate'].idxmax()]\n",
    "high_engagement = duration_analysis.loc[duration_analysis['avg_engagement'].idxmax()]\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"   Highest Completion: {sweet_spot['duration_bucket']} ({sweet_spot['completion_rate']:.1f}%)\")\n",
    "print(f\"   Highest Engagement: {high_engagement['duration_bucket']} ({high_engagement['avg_engagement']:.1f}%)\")\n",
    "\n",
    "# Compare extremes\n",
    "short = duration_analysis.iloc[0]\n",
    "long = duration_analysis.iloc[-1]\n",
    "completion_diff = short['completion_rate'] - long['completion_rate']\n",
    "\n",
    "print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "print(f\"      'Analysis of {duration_analysis['num_videos'].sum():,.0f} videos showed {sweet_spot['duration_bucket']}'\")\n",
    "print(f\"       had the highest completion rate at {sweet_spot['completion_rate']:.1f}%,'\")\n",
    "print(f\"       {completion_diff:.0f} points higher than longer content'\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "duration_analysis.plot(x='duration_bucket', y='completion_rate', kind='bar', ax=axes[0], legend=False, color='#3498db')\n",
    "axes[0].set_title('Completion Rate by Duration', fontweight='bold')\n",
    "axes[0].set_ylabel('Completion Rate (%)')\n",
    "axes[0].set_xlabel('Video Duration')\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "duration_analysis.plot(x='duration_bucket', y='avg_engagement', kind='bar', ax=axes[1], legend=False, color='#e74c3c')\n",
    "axes[1].set_title('Engagement Score by Duration', fontweight='bold')\n",
    "axes[1].set_ylabel('Engagement Score (%)')\n",
    "axes[1].set_xlabel('Video Duration')\n",
    "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Mobile Strategy & Device Trends\n",
    "**Business Question:** Is mobile viewing growing? Should we optimize for mobile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile trend analysis\n",
    "mobile_trend_query = \"\"\"\n",
    "SELECT\n",
    "    DATE_TRUNC('month', date) as month,\n",
    "    SUM(views_desktop) as desktop_views,\n",
    "    SUM(views_mobile) as mobile_views,\n",
    "    SUM(views_tablet) as tablet_views,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(SUM(views_mobile) * 100.0 / NULLIF(SUM(video_view), 0), 1) as mobile_percentage\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "mobile_trends = conn.execute(mobile_trend_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  MOBILE VIEWING TREND ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "display(mobile_trends)\n",
    "\n",
    "if len(mobile_trends) >= 2:\n",
    "    first_month = mobile_trends.iloc[0]\n",
    "    last_month = mobile_trends.iloc[-1]\n",
    "    \n",
    "    mobile_growth = last_month['mobile_percentage'] - first_month['mobile_percentage']\n",
    "    mobile_growth_pct = (mobile_growth / first_month['mobile_percentage'] * 100) if first_month['mobile_percentage'] > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(f\"   Mobile viewing: {first_month['mobile_percentage']:.1f}% ‚Üí {last_month['mobile_percentage']:.1f}%\")\n",
    "    print(f\"   Growth: +{mobile_growth:.1f} percentage points ({mobile_growth_pct:+.0f}%)\")\n",
    "    \n",
    "    if last_month['mobile_percentage'] > 30:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  STRATEGIC RECOMMENDATION:\")\n",
    "        print(f\"       Mobile now represents {last_month['mobile_percentage']:.1f}% of views\")\n",
    "        print(f\"       ‚Üí Mobile-first production approach recommended\")\n",
    "    \n",
    "    print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "    print(f\"      'Mobile viewing grew from {first_month['mobile_percentage']:.1f}% to {last_month['mobile_percentage']:.1f}%,'\")\n",
    "    print(f\"       justifying investment in mobile optimization (larger text, subtitles, vertical formats)'\")\n",
    "\n",
    "# Visualize trend\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(mobile_trends['month'].astype(str), mobile_trends['mobile_percentage'], \n",
    "        marker='o', linewidth=2, markersize=8, label='Mobile %', color='#e74c3c')\n",
    "ax.axhline(y=30, color='gray', linestyle='--', alpha=0.5, label='30% threshold')\n",
    "ax.set_title('Mobile Viewing Trend Over Time', fontweight='bold', fontsize=14)\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Mobile Percentage (%)')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, max(mobile_trends['mobile_percentage'].max() + 5, 40))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Content Archive Candidates\n",
    "**Business Question:** Which content is stale and should be archived or refreshed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stale content analysis (using dt_last_viewed)\n",
    "stale_content_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    video_id,\n",
    "    MAX(name) as video_name,\n",
    "    MAX(dt_last_viewed) as last_viewed,\n",
    "    SUM(video_view) as total_lifetime_views,\n",
    "    MAX(created_at)::DATE as created_date,\n",
    "    ROUND(MAX(video_duration) / 60.0, 1) as duration_minutes,\n",
    "    DATE_DIFF('day', MAX(dt_last_viewed)::DATE, CURRENT_DATE) as days_since_viewed\n",
    "FROM daily_analytics\n",
    "WHERE dt_last_viewed IS NOT NULL\n",
    "GROUP BY channel, video_id\n",
    "HAVING DATE_DIFF('day', MAX(dt_last_viewed)::DATE, CURRENT_DATE) > 180\n",
    "ORDER BY total_lifetime_views DESC\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    stale_content = conn.execute(stale_content_query).fetchdf()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"  STALE CONTENT CANDIDATES (Not viewed in 180+ days)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(stale_content) > 0:\n",
    "        display(stale_content.head(20))\n",
    "        \n",
    "        total_stale = len(stale_content)\n",
    "        total_stale_views = stale_content['total_lifetime_views'].sum()\n",
    "        \n",
    "        print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "        print(f\"   {total_stale} videos not viewed in 180+ days\")\n",
    "        print(f\"   These videos had {total_stale_views:,.0f} lifetime views (once valuable!)\")\n",
    "        \n",
    "        # Calculate potential storage savings\n",
    "        total_duration_hours = (stale_content['duration_minutes'].sum() / 60)\n",
    "        print(f\"   Total duration: {total_duration_hours:,.0f} hours of content\")\n",
    "        \n",
    "        print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "        print(f\"      'Identified {total_stale} videos not accessed in 6+ months.'\")\n",
    "        print(f\"       Archiving stale content reduced storage costs and improved search relevance'\")\n",
    "    else:\n",
    "        print(\"   ‚úì No stale content found - excellent content lifecycle management!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Could not analyze stale content: {e}\")\n",
    "    print(\"      (dt_last_viewed may not be populated in your dataset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Content Type Performance (if available)\n",
    "**Business Question:** Which content types drive the most engagement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content type performance\n",
    "content_type_query = \"\"\"\n",
    "SELECT\n",
    "    COALESCE(video_content_type, 'Unclassified') as content_type,\n",
    "    COUNT(DISTINCT video_id) as num_videos,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as completion_rate,\n",
    "    ROUND(AVG(video_duration) / 60.0, 1) as avg_duration_min\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY 1\n",
    "HAVING SUM(video_view) >= 100\n",
    "ORDER BY total_views DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "content_types = conn.execute(content_type_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  CONTENT TYPE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(content_types) > 1:\n",
    "    display(content_types)\n",
    "    \n",
    "    # Find insights\n",
    "    top_views = content_types.iloc[0]\n",
    "    top_engagement = content_types.loc[content_types['avg_engagement'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(f\"   Most Popular: '{top_views['content_type']}' with {top_views['total_views']:,.0f} views\")\n",
    "    print(f\"   Most Engaging: '{top_engagement['content_type']}' with {top_engagement['avg_engagement']:.1f}% engagement\")\n",
    "    \n",
    "    if top_engagement['content_type'] != top_views['content_type']:\n",
    "        engagement_diff = top_engagement['avg_engagement'] - top_views['avg_engagement']\n",
    "        print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "        print(f\"      '{top_engagement['content_type']}' content showed {engagement_diff:.0f}% higher engagement'\")\n",
    "        print(f\"       than {top_views['content_type']}, indicating opportunity to expand this content type'\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Content type data not available or not classified\")\n",
    "    print(\"      (This is normal if video_content_type field isn't populated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Engagement Drop-off Analysis\n",
    "**Business Question:** Where in videos do viewers drop off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement funnel analysis\n",
    "engagement_funnel_query = \"\"\"\n",
    "SELECT\n",
    "    channel,\n",
    "    ROUND(AVG(video_engagement_1), 1) as pct_started,\n",
    "    ROUND(AVG(video_engagement_25), 1) as pct_reached_25,\n",
    "    ROUND(AVG(video_engagement_50), 1) as pct_reached_50,\n",
    "    ROUND(AVG(video_engagement_75), 1) as pct_reached_75,\n",
    "    ROUND(AVG(video_engagement_100), 1) as pct_completed\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "GROUP BY channel\n",
    "ORDER BY pct_completed DESC\n",
    "\"\"\"\n",
    "\n",
    "engagement_funnel = conn.execute(engagement_funnel_query).fetchdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  ENGAGEMENT DROP-OFF BY CHANNEL\")\n",
    "print(\"=\"*80)\n",
    "display(engagement_funnel)\n",
    "\n",
    "# Calculate overall drop-off\n",
    "overall_funnel = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        ROUND(AVG(video_engagement_1), 1) as started,\n",
    "        ROUND(AVG(video_engagement_25), 1) as reached_25,\n",
    "        ROUND(AVG(video_engagement_50), 1) as reached_50,\n",
    "        ROUND(AVG(video_engagement_75), 1) as reached_75,\n",
    "        ROUND(AVG(video_engagement_100), 1) as completed\n",
    "    FROM daily_analytics\n",
    "    WHERE video_view > 0\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "if len(overall_funnel) > 0:\n",
    "    values = overall_funnel.iloc[0].values\n",
    "    drop_0_25 = values[0] - values[1]\n",
    "    drop_25_50 = values[1] - values[2]\n",
    "    drop_50_75 = values[2] - values[3]\n",
    "    drop_75_100 = values[3] - values[4]\n",
    "    \n",
    "    print(f\"\\nüí° OVERALL ENGAGEMENT FUNNEL:\")\n",
    "    print(f\"   Started:      {values[0]:.1f}%\")\n",
    "    print(f\"   Reached 25%:  {values[1]:.1f}% (drop: {drop_0_25:.1f} points)\")\n",
    "    print(f\"   Reached 50%:  {values[2]:.1f}% (drop: {drop_25_50:.1f} points)\")\n",
    "    print(f\"   Reached 75%:  {values[3]:.1f}% (drop: {drop_50_75:.1f} points)\")\n",
    "    print(f\"   Completed:    {values[4]:.1f}% (drop: {drop_75_100:.1f} points)\")\n",
    "    \n",
    "    # Find biggest drop-off\n",
    "    drops = [drop_0_25, drop_25_50, drop_50_75, drop_75_100]\n",
    "    stages = ['0-25%', '25-50%', '50-75%', '75-100%']\n",
    "    biggest_drop_idx = drops.index(max(drops))\n",
    "    \n",
    "    print(f\"\\n   Biggest drop-off: {stages[biggest_drop_idx]} ({max(drops):.1f} percentage points)\")\n",
    "    \n",
    "    if biggest_drop_idx == 0:\n",
    "        print(f\"\\n   üìå INTERVIEW TALKING POINT:\")\n",
    "        print(f\"      'Analysis revealed {drop_0_25:.1f}% of viewers drop off in first 25% of videos.'\")\n",
    "        print(f\"       Recommended stronger opening hooks and front-loading key messages'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: ROI Summary & Business Value\n",
    "**Business Question:** What's the overall business value delivered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business value summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  BUSINESS VALUE SUMMARY FOR INTERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get key metrics\n",
    "summary_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(DISTINCT video_id) as total_videos,\n",
    "    COUNT(DISTINCT channel) as total_channels,\n",
    "    SUM(video_view) as total_views,\n",
    "    ROUND(AVG(engagement_score), 1) as avg_engagement,\n",
    "    ROUND(AVG(video_engagement_100), 1) as avg_completion,\n",
    "    SUM(video_seconds_viewed) / 3600.0 as total_watch_hours\n",
    "FROM daily_analytics\n",
    "WHERE video_view > 0\n",
    "\"\"\"\n",
    "\n",
    "summary = conn.execute(summary_query).fetchdf().iloc[0]\n",
    "\n",
    "print(\"\\nüìä QUANTIFIABLE METRICS:\")\n",
    "print(f\"   Total Videos Analyzed: {summary['total_videos']:,.0f}\")\n",
    "print(f\"   Total Channels: {summary['total_channels']:.0f}\")\n",
    "print(f\"   Total Views: {summary['total_views']:,.0f}\")\n",
    "print(f\"   Total Watch Time: {summary['total_watch_hours']:,.0f} hours\")\n",
    "print(f\"   Average Engagement: {summary['avg_engagement']:.1f}%\")\n",
    "print(f\"   Average Completion: {summary['avg_completion']:.1f}%\")\n",
    "\n",
    "print(\"\\nüí° KEY TALKING POINTS FOR INTERVIEWS:\")\n",
    "print(\"\\n1. SCALE:\")\n",
    "print(f\"   'Built analytics infrastructure covering {summary['total_videos']:,.0f} videos across\")\n",
    "print(f\"    {summary['total_channels']:.0f} channels, tracking {summary['total_views']:,.0f} views'\")\n",
    "\n",
    "print(\"\\n2. INSIGHTS ENABLED:\")\n",
    "print(\"   'Transformed fragmented data into actionable insights that informed:\")\n",
    "print(\"    - Content strategy (optimal duration, content types)\")\n",
    "print(\"    - Channel rationalization (consolidate underperformers)\")\n",
    "print(\"    - Device optimization (mobile-first approach)\")\n",
    "print(\"    - Training effectiveness (completion rate improvement)'\")\n",
    "\n",
    "print(\"\\n3. BUSINESS IMPACT:\")\n",
    "print(\"   'Data-driven decisions led to:\")\n",
    "print(\"    - Higher content completion rates (quantified by duration optimization)\")\n",
    "print(\"    - Reduced operational costs (channel consolidation)\")\n",
    "print(\"    - Improved mobile engagement (optimization based on trends)\")\n",
    "print(\"    - Better resource allocation (invest in high-engagement channels)'\")\n",
    "\n",
    "print(\"\\n4. STRATEGIC INFLUENCE:\")\n",
    "print(\"   'Shifted Internal Communications from intuition-based to evidence-based:\")\n",
    "print(\"    - Executive reports now include engagement metrics\")\n",
    "print(\"    - Content producers receive performance feedback\")\n",
    "print(\"    - Budget decisions tied to channel performance data'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  TIP: Replace placeholder numbers above with your actual findings!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BONUS: Custom Analysis Section\n",
    "Add your own queries here to dig deeper into specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here\n",
    "# Example: Analyze specific video\n",
    "\n",
    "# video_details_query = \"\"\"\n",
    "# SELECT *\n",
    "# FROM daily_analytics\n",
    "# WHERE video_id = 'YOUR_VIDEO_ID'\n",
    "# ORDER BY date\n",
    "# \"\"\"\n",
    "\n",
    "# results = conn.execute(video_details_query).fetchdf()\n",
    "# display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "print(\"\\n‚úì Analysis complete! Database connection closed.\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Review the insights above and note specific numbers\")\n",
    "print(\"2. Identify 2-3 strongest business impact examples\")\n",
    "print(\"3. Craft your STAR responses using actual metrics from your data\")\n",
    "print(\"4. Practice articulating business value, not technical details\")\n",
    "print(\"\\nGood luck with your interviews! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
